{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Pipelines for Text Analysis \n",
    "\n",
    "June 25, 2017 &middot; Data Intelligence Conference &middot; Capitol One\n",
    "\n",
    "## Visual Topic Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import nltk \n",
    "import sklearn \n",
    "\n",
    "#import yellowbrick as yb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use development version of Yellowbrick \n",
    "import sys \n",
    "sys.path.append(\"/Users/benjamin/Repos/ddl/yellowbrick\")\n",
    "import yellowbrick as yb\n",
    "\n",
    "# Notebook specific utilities \n",
    "from utils import * \n",
    "from corpus import BaleenPickledCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baleen corpus contains 1,308 files in 2 categories.\n",
      "Structured as:\n",
      "    25,055 paragraphs (19.155 mean paragraphs per file)\n",
      "    41,659 sentences (1.663 mean sentences per paragraph).\n",
      "Word count of 939,541 with a vocabulary of 41,153 (22.830 lexical diversity).\n",
      "Corpus scan took 1.899251937866211 seconds.\n"
     ]
    }
   ],
   "source": [
    "FIXTURES   = os.path.join(os.getcwd(), \"fixtures\")\n",
    "ARTICLES   = os.path.join(FIXTURES, \"articles\")\n",
    "\n",
    "categories = [\"news\", \"politics\"]\n",
    "corpus     = BaleenPickledCorpusReader(ARTICLES)\n",
    "print(corpus.describes(categories=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from transform import * \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple LDA Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('norm', TextNormalizer()), \n",
    "    ('tfidf',  TfidfVectorizer(\n",
    "        tokenizer=identity, preprocessor=None, lowercase=False\n",
    "    )),\n",
    "    ('lda', LatentDirichletAllocation(n_topics=25)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00582492,  0.00582492,  0.00582492, ...,  0.00582492,\n",
       "         0.00582492,  0.00582492],\n",
       "       [ 0.01689608,  0.01689608,  0.01689608, ...,  0.01689608,\n",
       "         0.01689608,  0.59449397],\n",
       "       [ 0.00303881,  0.00303881,  0.00303881, ...,  0.00303881,\n",
       "         0.00303881,  0.09972504],\n",
       "       ..., \n",
       "       [ 0.00666966,  0.00666966,  0.00666966, ...,  0.00666966,\n",
       "         0.00666966,  0.00666966],\n",
       "       [ 0.00465198,  0.00465198,  0.00465198, ...,  0.00465198,\n",
       "         0.00465198,  0.00465198],\n",
       "       [ 0.00424296,  0.00424296,  0.00424296, ...,  0.00424296,\n",
       "         0.00424296,  0.00424296]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = documents(corpus, categories=categories)\n",
    "model.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topn_words(model, n=10, vectorizer=None):\n",
    "    vectorizer = vectorizer or model.named_steps['tfidf']\n",
    "    model  = model if hasattr(model, 'components_') else model.steps[-1][1]\n",
    "    names  = vectorizer.get_feature_names()\n",
    "    output = []\n",
    "    \n",
    "    for idx, topic in enumerate(model.components_):\n",
    "\n",
    "        features = topic.argsort()[:-n - 1: -1]\n",
    "        tokens = [names[i] for i in features]\n",
    "        \n",
    "        output.append(\"Topic #{}\".format(idx)) \n",
    "        output.append(\" \".join(tokens))\n",
    "    \n",
    "    print(\"\\n\".join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0\n",
      "× moveable fsg erades hemingway bookend rises persistently 不开吧通常发生 于是就有了做个感应小夜灯的想法\n",
      "Topic #1\n",
      "consul dundar crustal ionosphere cumhuriyet tulay karadeniz erdem reutersturkey adequacy\n",
      "Topic #2\n",
      "kepler afac ganek hsueh hedging swatch longson pauley cernobbio roubini\n",
      "Topic #3\n",
      "fitch biac abercrombie wool wangthe bauhaus aqr aeronautical nyembo mbuguje\n",
      "Topic #4\n",
      "s7 dinklage abaa promos antiquarian theseâ squaretrade youtubethe 317 editions\n",
      "Topic #5\n",
      "copycat nikon ele petapixel knockoff laneil optical lenses theirâ manfred\n",
      "Topic #6\n",
      "microcephaly chefâ imagesif georgesâ tang traces hengli amelia bodily infects\n",
      "Topic #7\n",
      "cleary kerlan cpp draghi rocketskates motorize acton praet packt ecb\n",
      "Topic #8\n",
      "cidra kadokawa manga retailing hbg classifiedâ anime harmonics yanai uniqlo\n",
      "Topic #9\n",
      "heroine eeoc qualidade primeira é katniss everdeen lua horses broughtâ\n",
      "Topic #10\n",
      "greenback laing contraction holliday vellitt suydam lovecraft ism markel ~~~\n",
      "Topic #11\n",
      "lev fairbanks iditarod levs haveâ snowâ northâ nome railroadâ recordâ\n",
      "Topic #12\n",
      "leeann rewind cleanser experiencer fanfreakingtastic machu hipsteresque peregrine sadsadbookfunk litsy\n",
      "Topic #13\n",
      "eyre sinjar fass vom mallory vous parlez francais ortberg pseudonymous\n",
      "Topic #14\n",
      "handbag seppälä cottage 1q brenke stipend winnie caldecott nar kors\n",
      "Topic #15\n",
      "rogen waldo homeric debuted iliad dreyfuss 715 getaway docastaway hoeller\n",
      "Topic #16\n",
      "liew wittgenstein esperanto 1881 comeswell grindr angelika icee protip terruso\n",
      "Topic #17\n",
      "afflalo patou facebookfollow passman fairway insiderâ govt foodâ poundstone shopify\n",
      "Topic #18\n",
      "stills gaiman conman mythological fremantlemedia mollify crosby nash browning mcshane\n",
      "Topic #19\n",
      "didion eco hyperions callebaut amlankusum jaypee architecturesthe architectures agroecologist curvilinear\n",
      "Topic #20\n",
      "say trump year one make new get people would go\n",
      "Topic #21\n",
      "lba beau kwame masterson kutcher colt cim benton supervillainesses catwoman\n",
      "Topic #22\n",
      "ulster leinster quire quill puppies rbs gou spyjinx nacewa dobbie\n",
      "Topic #23\n",
      "haram boko jeep chs bacevich buhari halo ssangyong ec cco\n",
      "Topic #24\n",
      "posts related cuddy majka hubspot disrupted nonverbal newsweek doppelgängers believability\n"
     ]
    }
   ],
   "source": [
    "topn_words(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas:\n",
    "\n",
    "- Topic Word Frequencies \n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
